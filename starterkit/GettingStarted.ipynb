{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from starterkit.dataset import Drive360Loader\n",
    "\n",
    "\n",
    "config = json.load(open('./starterkit/config.json'))\n",
    "\n",
    "train_loader = Drive360Loader(config, 'train')\n",
    "validation_loader = Drive360Loader(config, 'validation')\n",
    "test_loader = Drive360Loader(config, 'test')\n",
    "\n",
    "print('Loaded train loader with the following data available as a dict.')\n",
    "print(train_loader.drive360.dataframe.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from collections import OrderedDict\n",
    "from itertools import chain\n",
    "from typing import Dict\n",
    "from typing import Set\n",
    "\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "\n",
    "class SlowFusionModel(nn.Module):\n",
    "\n",
    "    def __init__(self, cameras: Set[str], num_frames_per_camera: int):\n",
    "        super().__init__()\n",
    "        self.cameras = cameras\n",
    "        self.num_frames_per_camera = num_frames_per_camera\n",
    "\n",
    "        # Build towers to extract features from each frame from each camera\n",
    "        resnet = models.resnet34(pretrained=True)\n",
    "        self.feature_extractor = nn.Sequential(*list(resnet.children())[:6])\n",
    "\n",
    "        # Fuse features of all frames for each camera\n",
    "        self.early_fusions: Dict[str, nn.Module] = dict()\n",
    "        for camera in self.cameras:\n",
    "            self.early_fusions[camera] = self._make_early_fusion()\n",
    "\n",
    "        # Fuse volume from each camera\n",
    "        self.late_fusion = self._make_late_fusion()\n",
    "\n",
    "        # Build two regression heads for each target\n",
    "        self.speed_head = self._make_regression_head()\n",
    "        self.angle_head = self._make_regression_head()\n",
    "\n",
    "    def forward(self, x: Dict[str, Dict[int, torch.Tensor]]):\n",
    "        # Extract features from each frame from each camera\n",
    "        features = {camera: [self.feature_extractor(x[camera][frame]) for frame in \n",
    "                             range(self.num_frames_per_camera)]\n",
    "                    for camera in self.cameras}\n",
    "\n",
    "        # Fuse features of all frames for each camera\n",
    "        early_fusions_out: Dict[str, torch.Tensor] = dict()\n",
    "        for camera in self.cameras:\n",
    "            frames = tuple(features[camera])\n",
    "            frames = torch.cat(frames, 1)\n",
    "            early_fusions_out[camera] = self.early_fusions[camera](frames)\n",
    "\n",
    "        # Fuse volume from each camera\n",
    "        cameras = tuple(early_fusions_out.values())\n",
    "        cameras = torch.cat(cameras, 1)\n",
    "        late_fusion_out = self.late_fusion(cameras)\n",
    "\n",
    "        # Perform prediction on both regression heads\n",
    "        late_fusion_out = late_fusion_out.view(late_fusion_out.size(0), -1)\n",
    "        speed_head_out = self.speed_head(late_fusion_out)\n",
    "        angle_head_out = self.angle_head(late_fusion_out)\n",
    "\n",
    "        return {'canSpeed': torch.squeeze(speed_head_out),\n",
    "                'canSteering': torch.squeeze(angle_head_out)}\n",
    "\n",
    "    def cuda(self, device: str = None):\n",
    "        super().cuda()\n",
    "        for camera in self.cameras:\n",
    "            self.early_fusions[camera].cuda()\n",
    "        return self\n",
    "\n",
    "    def _make_early_fusion(self) -> nn.Module:\n",
    "        num_filters = 128 * self.num_frames_per_camera\n",
    "        resnet = models.resnet34(pretrained=False)\n",
    "        return nn.Sequential(OrderedDict({\n",
    "            'block1': self._make_block(num_filters, 512),\n",
    "            'block2': self._make_block(512, 256),\n",
    "            'block3': self._make_block(256, 128),\n",
    "            'resnet': nn.Sequential(*list(resnet.children())[6:8]),\n",
    "        }))\n",
    "\n",
    "    def _make_late_fusion(self) -> nn.Module:\n",
    "        num_filters = 512 * len(self.cameras)\n",
    "        resnet = models.resnet34(pretrained=False)\n",
    "        return nn.Sequential(OrderedDict({\n",
    "            'block1': self._make_block(num_filters, 512),\n",
    "            'resnet': nn.Sequential(*list(resnet.children())[8:9]),\n",
    "        }))\n",
    "\n",
    "    def _make_regression_head(self) -> nn.Module:\n",
    "        return nn.Sequential(OrderedDict({\n",
    "            'fc1': nn.Linear(512, 64),\n",
    "            'relu1': nn.ReLU(),\n",
    "            'fc2': nn.Linear(64, 32),\n",
    "            'relu2': nn.ReLU(),\n",
    "            'fc3': nn.Linear(32, 1),\n",
    "        }))\n",
    "\n",
    "    def _make_block(self, in_channels: int, out_channels: int) -> nn.Module:\n",
    "        return nn.Sequential(OrderedDict({\n",
    "            'conv': nn.Conv2d(in_channels, out_channels, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
    "            'bn': nn.BatchNorm2d(out_channels, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            'relu': nn.ReLU(),\n",
    "        }))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SomeDrivingModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SomeDrivingModel, self).__init__()\n",
    "        final_concat_size = 0\n",
    "        \n",
    "        # Main CNN\n",
    "        cnn = models.resnet34(pretrained=True)\n",
    "        self.features = nn.Sequential(*list(cnn.children())[:-1])\n",
    "        self.intermediate = nn.Sequential(nn.Linear(\n",
    "                          cnn.fc.in_features, 128),\n",
    "                          nn.ReLU())\n",
    "        final_concat_size += 128\n",
    "\n",
    "        # Main LSTM\n",
    "        self.lstm = nn.LSTM(input_size=128,\n",
    "                            hidden_size=64,\n",
    "                            num_layers=3,\n",
    "                            batch_first=False)\n",
    "        final_concat_size += 64\n",
    "        \n",
    "        # Angle Regressor\n",
    "        self.control_angle = nn.Sequential(\n",
    "            nn.Linear(final_concat_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "        # Speed Regressor\n",
    "        self.control_speed = nn.Sequential(\n",
    "            nn.Linear(final_concat_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, data):\n",
    "        module_outputs = []\n",
    "        lstm_i = []\n",
    "        # Loop through temporal sequence of\n",
    "        # front facing camera images and pass \n",
    "        # through the cnn.\n",
    "        for k, v in data['cameraFront'].items():\n",
    "            x = self.features(v)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            x = self.intermediate(x)\n",
    "            lstm_i.append(x)\n",
    "            # feed the current front facing camera\n",
    "            # output directly into the \n",
    "            # regression networks.\n",
    "            if k == 0:\n",
    "                module_outputs.append(x)\n",
    "\n",
    "        # Feed temporal outputs of CNN into LSTM\n",
    "        i_lstm, _ = self.lstm(torch.stack(lstm_i))\n",
    "        module_outputs.append(i_lstm[-1])\n",
    "        \n",
    "        # Concatenate current image CNN output \n",
    "        # and LSTM output.\n",
    "        x_cat = torch.cat(module_outputs, dim=-1)\n",
    "        \n",
    "        # Feed concatenated outputs into the \n",
    "        # regession networks.\n",
    "        prediction = {'canSteering': torch.squeeze(self.control_angle(x_cat)),\n",
    "                      'canSpeed': torch.squeeze(self.control_speed(x_cat))}\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = SlowFusionModel(cameras={'cameraFront'}, num_frames_per_camera=4)\n",
    "#model = SomeDrivingModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch\n",
    "\n",
    "num_epochs = 40\n",
    "log_every = 100  \n",
    "criterion = nn.MSELoss()  # nn.SmoothL1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=1, verbose=True)\n",
    "model.train()\n",
    "\n",
    "\n",
    "def validate(model, criterion, data_loader):\n",
    "    val_running_loss = 0.0\n",
    "    for data, target in data_loader:\n",
    "        data, target = sent_to_device(data, target, config)\n",
    "        pred = model(data)\n",
    "        loss = compute_loss(pred, target, criterion)\n",
    "        val_running_loss += loss.item()\n",
    "    return val_running_loss / len(validation_loader)\n",
    "\n",
    "\n",
    "def compute_loss(prediction, target, criterion):\n",
    "    return criterion(prediction['canSpeed'], target['canSpeed']) + \\\n",
    "            2 * criterion(prediction['canSteering'], target['canSteering'])\n",
    "\n",
    "\n",
    "def sent_to_device(data, target, config):\n",
    "    if config['cuda']['use']:\n",
    "        data = {cam: ({idx: frame.cuda() for idx, frame in frames.items()} \n",
    "                if isinstance(frames, dict) else frames.cuda())   \n",
    "                for cam, frames in data.items()}\n",
    "        target = {cam: labels.cuda() for cam, labels in target.items()}\n",
    "    return data, target\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # Training\n",
    "    train_running_loss = 0.0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = sent_to_device(data, target, config)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(data)\n",
    "        loss = compute_loss(pred, target, criterion)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_running_loss += loss.item()\n",
    "        if batch_idx and batch_idx % log_every == 0:  \n",
    "            train_loss = train_running_loss / log_every\n",
    "            print('[epoch: %d, batch:  %5d] training loss: %.5f' % (epoch, batch_idx, train_loss))\n",
    "            train_running_loss = 0.0\n",
    "            \n",
    "    torch.cuda.empty_cache()\n",
    "    model.cuda()\n",
    "    \n",
    "    # Validation\n",
    "    val_loss = validate(model, criterion, validation_loader)\n",
    "    scheduler.step(val_loss)\n",
    "    print('[epoch: %d] validation loss: %.5f' % (epoch, val_loss))\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    model.cuda()\n",
    "    \n",
    "    # Save model\n",
    "    torch.save(model.state_dict(), f\"./model-{epoch}.torch\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "model_name = \"model-25-l2\"\n",
    "model.load_state_dict(torch.load(f\"./{model_name}.torch\"))\n",
    "model.cuda()\n",
    "\n",
    "model.eval()\n",
    "running_mse = 0.0\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(validation_loader):\n",
    "        data, target = sent_to_device(data, target, config)\n",
    "        prediction = model(data)\n",
    "        running_mse += (np.square(prediction['canSpeed'].cpu() - target['canSpeed'].cpu())).mean() + \\\n",
    "                        (np.square(prediction['canSteering'].cpu() - target['canSteering'].cpu())).mean()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(batch_idx)\n",
    "    print(\"MSE:\", running_mse / len(validation_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_targets = config['target']['normalize']\n",
    "target_mean = config['target']['mean']\n",
    "target_std = config['target']['std']\n",
    "\n",
    "def add_results(results, output):\n",
    "    steering = np.squeeze(output['canSteering'].cpu().data.numpy())\n",
    "    speed = np.squeeze(output['canSpeed'].cpu().data.numpy())\n",
    "    if normalize_targets:\n",
    "        steering = (steering*target_std['canSteering'])+target_mean['canSteering']\n",
    "        speed = (speed*target_std['canSpeed'])+target_mean['canSpeed']\n",
    "    if np.isscalar(steering):\n",
    "        steering = [steering]\n",
    "    if np.isscalar(speed):\n",
    "        speed = [speed]\n",
    "    results['canSteering'].extend(steering)\n",
    "    results['canSpeed'].extend(speed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "label = datetime.now().strftime(\"%d-%m-%Y--%H:%M:%S\")\n",
    "file = f'./submission--{model_name}--{label}.csv'\n",
    "results = {'canSteering': [],\n",
    "           'canSpeed': []}\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        data, target = sent_to_device(data, target, config)\n",
    "        prediction1 = l1_model(data)\n",
    "        prediction2 = l2_model(data)\n",
    "        prediction = {\n",
    "            'canSpeed': (prediction1['canSpeed'] + prediction2['canSpeed']) / 2,\n",
    "            'canSteering': (prediction1['canSteering'] + prediction2['canSteering']) / 2,\n",
    "        }\n",
    "        add_results(results, prediction)\n",
    "        \n",
    "df = pd.DataFrame.from_dict(results)\n",
    "df.to_csv(file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
